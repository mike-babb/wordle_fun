{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da60781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mike babb\n",
    "# 2022 03 03 \n",
    "# solve wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dd7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pickle\n",
    "import os\n",
    "import sqlite3\n",
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c393ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcf5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to load a pickle\n",
    "def load_pickle(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, 'rb') as handle:\n",
    "            de_pickle = pickle.load(handle)\n",
    "    else:\n",
    "        de_pickle = None\n",
    "        print(\"file does not exist\")\n",
    "    return de_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b82deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_13968\\773985408.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  de_pickle = pickle.load(handle)\n"
     ]
    }
   ],
   "source": [
    "char_matrix = load_pickle(file_name = 'char_matrix.pkl')\n",
    "letter_dict = load_pickle(file_name = 'letter_dict.pkl')\n",
    "letter_rank_dict = load_pickle(file_name ='letter_rank_dict.pkl')\n",
    "word_df = load_pickle(file_name = 'word_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec971d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>word_id</th>\n",
       "      <th>n_unique_chars</th>\n",
       "      <th>word_score</th>\n",
       "      <th>word_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20449.0</td>\n",
       "      <td>-2134795976539657997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>aaron</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20642.0</td>\n",
       "      <td>5168226787426640364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaca</td>\n",
       "      <td>abaca</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20009.0</td>\n",
       "      <td>7298090979578241273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>aback</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15456.0</td>\n",
       "      <td>6926502400987240042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abaff</td>\n",
       "      <td>abaff</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14038.0</td>\n",
       "      <td>7931255010571806167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  word_id  n_unique_chars  word_score           word_group\n",
       "0  aalii  aalii        0               3     20449.0 -2134795976539657997\n",
       "1  Aaron  aaron        1               4     20642.0  5168226787426640364\n",
       "2  abaca  abaca        2               3     20009.0  7298090979578241273\n",
       "3  aback  aback        3               4     15456.0  6926502400987240042\n",
       "4  abaff  abaff        4               3     14038.0  7931255010571806167"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490c3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the word id\n",
    "word_id_list = word_df['word_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ed9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_words(toss_letters = None, \n",
    "                  known_pos = None, known_anti_pos = None, verbose = True):\n",
    "    \"\"\"\n",
    "    toss_letters: list. Letters known to be in the word\n",
    "    known_pos: list. Letters in the correct position\n",
    "    known_anti_pos: list. Letters in the incorrect position\n",
    "    \n",
    "    entering no values returns a list of suggested starting words, ranked by the frequency\n",
    "    of each letter's occurence. Higher ranked words contain letters that occur more\n",
    "    frequently across all five-digit words.    \n",
    "    \"\"\"    \n",
    "       \n",
    "    # intialize lists if necessary\n",
    "    blank_count = 0\n",
    "    \n",
    "    if toss_letters is None:\n",
    "        toss_letters = ['']*5\n",
    "        blank_count += 1\n",
    "    if known_pos is None:\n",
    "        known_pos = ['']*5\n",
    "        blank_count += 1    \n",
    "    if known_anti_pos is None:\n",
    "        known_anti_pos = ['']*5\n",
    "        blank_count += 1\n",
    "        \n",
    "    for i_kap in range(len(known_anti_pos)):\n",
    "        if known_pos[i_kap] != '':\n",
    "            known_anti_pos[i_kap] = ''\n",
    "    \n",
    "    # check if the user supplied values\n",
    "    if blank_count <3:\n",
    "    \n",
    "        # use this list to winnow down selections\n",
    "        zero_id_list = np.zeros(shape = word_id_list.shape, dtype = int)\n",
    "        \n",
    "        # build the list of letters that are known\n",
    "        keep_letters = set(known_pos)\n",
    "        for kap in known_anti_pos:\n",
    "            keep_letters = keep_letters.union(kap)\n",
    "                               \n",
    "        for kl in keep_letters:\n",
    "            if kl != '':\n",
    "                for jl in kl:\n",
    "                    zero_id_list[char_matrix[:, letter_dict[jl]]>0] += 1\n",
    "                \n",
    "        # remove a word when there is an incorrect letter\n",
    "        for tl in toss_letters:\n",
    "            if tl != '':\n",
    "                zero_id_list[char_matrix[:, letter_dict[tl]]>0] -= 1\n",
    "        \n",
    "        # this is the list of word_ids that have letters of interest\n",
    "        curr_word_five_id_list = word_id_list[zero_id_list >= (len(keep_letters) - 1)]\n",
    "\n",
    "        # select from the data frame based on the word id\n",
    "        curr_df = word_df.loc[word_df['word_id'].isin(curr_word_five_id_list),\n",
    "                          ['lcase', 'word_score', 'n_unique_chars']]\n",
    "\n",
    "        # the list of possible words, after removing words with incorrect letters\n",
    "        pos_words = curr_df['lcase'].values        \n",
    "\n",
    "        # we're going to make use of the lists of letters with known positions\n",
    "        # and letters known to be in the word, but in the incorrect post\n",
    "        output_list = np.full(shape = pos_words.shape, fill_value=True)\n",
    "        #print(known_pos)\n",
    "        #print(known_anti_pos)\n",
    "        # enumerate each word        \n",
    "        for i_pos_word, pos_word in enumerate(pos_words):\n",
    "            #print(pw)            \n",
    "            # enumerate each character in each word\n",
    "            for ii_pwl, i_pwl in enumerate(pos_word):\n",
    "                # known positions\n",
    "                # based on the index, remove the word if the letters do not match\n",
    "                if known_pos[ii_pwl] != '':\n",
    "                    #print(kp[ii_pw], i_pw)\n",
    "                    if known_pos[ii_pwl] != i_pwl:\n",
    "                        output_list[i_pos_word] = False\n",
    "                # known anti-positions                \n",
    "                # based on the index, remove the word if the letters do match\n",
    "                if known_anti_pos[ii_pwl] != '':\n",
    "                    curr_known_anti_pos = known_anti_pos[ii_pwl]\n",
    "                    for jj_pwl in curr_known_anti_pos:\n",
    "                        #print(kap[ii_pwl], i_pwl)\n",
    "                        #known_anti_pos[ii_pwl]\n",
    "                        if jj_pwl == i_pwl:\n",
    "                            output_list[i_pos_word] = False\n",
    "        \n",
    "        # the list of possible words\n",
    "        pos_words = pos_words[output_list]\n",
    "        \n",
    "        wdf = word_df.loc[word_df['lcase'].isin(pos_words), ['lcase', 'n_unique_chars', 'word_score']]\n",
    "        wdf = wdf.sort_values(by = ['n_unique_chars', 'word_score'],\n",
    "                                 ascending=False)\n",
    "                \n",
    "    else:\n",
    "        # the initial list of words to choose from, sorted by unique characters and word score\n",
    "        wdf = word_df.sort_values(by = ['n_unique_chars', 'word_score'],\n",
    "                                 ascending=False)\n",
    "    \n",
    "    pos_words = wdf['lcase']\n",
    "    pos_words = pos_words.tolist()\n",
    "    if verbose:\n",
    "        #print(len(pos_words))\n",
    "        print(pos_words)\n",
    "    return len(pos_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f531e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f502eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curio', 'choir']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# letters known to not be in the word\n",
    "# can be a list any length long\n",
    "toss_letters = 'plaen'\n",
    "\n",
    "# letters in the correct position\n",
    "# list with length five\n",
    "kp = ['c','','','i','']\n",
    "#kp = None\n",
    "\n",
    "# letters in the word, but in the incorrect spot\n",
    "# list with \n",
    "kap = ['', 'o', '', '', '']\n",
    "#kap = None\n",
    "\n",
    "# iterate until a solution is found\n",
    "suggest_words(toss_letters = toss_letters, known_pos = kp, known_anti_pos = kap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61aa380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f5d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f62b4-5123-4f15-9177-cdf8271a3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_word_list = []\n",
    "kp = ['','','','','']\n",
    "kap = ['', '', '', '', '']\n",
    "prev_letter = word_df['lcase'].iloc[0][0]\n",
    "print(prev_letter)\n",
    "for cw in word_df['lcase'].tolist():\n",
    "    curr_letter = cw[0]\n",
    "    if prev_letter != curr_letter:\n",
    "        print(curr_letter)\n",
    "        prev_letter = curr_letter    \n",
    "\n",
    "    #print(cw)\n",
    "    outcome = suggest_words(toss_letters = cw, known_pos = kp, known_anti_pos = kap, verbose = False)\n",
    "    remove_word_list.append([cw, outcome])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0a17d-28f0-477a-852b-174d4ec8a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the best word to start with?\n",
    "best_start_word = pd.DataFrame(data = remove_word_list, columns = ['lcase', 'n_next_word'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b94daeb-0d31-4b47-8840-71efa61c83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start_word = best_start_word.sort_values(by = 'n_next_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4284d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start_word.to_excel(excel_writer = 'start_words.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e11946",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56416ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
